{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7293558a-5721-4b7f-9592-1519a852ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0b02f-54eb-4143-b3be-e77d946259ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist import PathMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9f40c-a719-40da-8a84-639921b87171",
   "metadata": {},
   "source": [
    "### Initializing Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2600b34a-8728-4bd7-8743-f00fb649cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Weights and Biases\n",
    "wandb.init(project=\"pathmnist-classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec105e5-13a2-4fe6-ada7-a9248ffca229",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2bfe5d-b869-4fa3-bfa1-d31e16aeb39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(64, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "transform_val_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607320a-6d81-4b1b-a88a-8f650c664472",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PathMNIST(split=\"train\", size=64, transform=transform_train, download=True, target_transform=lambda x: torch.tensor(x, dtype=torch.long).squeeze())\n",
    "val_dataset = PathMNIST(split=\"val\", size=64, transform=transform_val_test, download=True, target_transform=lambda x: torch.tensor(x, dtype=torch.long).squeeze())\n",
    "test_dataset = PathMNIST(split=\"test\", size=64, transform=transform_val_test, download=True, target_transform=lambda x: torch.tensor(x, dtype=torch.long).squeeze())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bd7b7-7c77-430c-850c-69b60cfbc717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data size\n",
    "for images, labels in train_loader:\n",
    "    print(f\"Input shape: {images.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3657b-e8cc-4c28-9691-e03ea84ce260",
   "metadata": {},
   "source": [
    "### Functions for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d48be3-1870-4ae6-acb6-6d8cd8197d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc = accuracy_score(all_labels, all_preds)\n",
    "        val_acc = evaluate_model(model, val_loader, criterion)\n",
    "\n",
    "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": running_loss / len(train_loader), \"train_acc\": train_acc, \"val_acc\": val_acc})\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if early_stopping(val_acc):\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105f915-119f-464b-981e-97f993982a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.epochs_without_improvement = 0\n",
    "\n",
    "    def __call__(self, val_acc):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_acc\n",
    "            return False\n",
    "        elif val_acc < self.best_score + self.delta:\n",
    "            self.epochs_without_improvement += 1\n",
    "            if self.epochs_without_improvement >= self.patience:\n",
    "                return True\n",
    "        else:\n",
    "            self.best_score = val_acc\n",
    "            self.epochs_without_improvement = 0\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293fe7a-15ac-4acc-b50f-f3cb7be51cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, criterion):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            all_preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_acc = accuracy_score(all_labels, all_preds)\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69094cb3-157c-4976-a1d3-a425232ba0bc",
   "metadata": {},
   "source": [
    "### CNN Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036082a7-676a-4dd9-b0cc-c85f277fab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearningModel(nn.Module):\n",
    "    def __init__(self, num_classes=9, pretrained=True):\n",
    "        super(TransferLearningModel, self).__init__()\n",
    "        \n",
    "        # Wczytanie pretrenowanego modelu ResNet18\n",
    "        self.base_model = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Zastąpienie ostatniej w pełni połączonej warstwy klasyfikatora\n",
    "        # Dopasowanie wyjścia do liczby klas w zadaniu\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b7be7-482b-4b98-b8e3-a0f65068022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearningModelResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=9, pretrained=True):\n",
    "        super(TransferLearningModelResNet50, self).__init__()\n",
    "        \n",
    "        # Wczytanie pretrenowanego modelu ResNet18\n",
    "        self.base_model = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Zastąpienie ostatniej w pełni połączonej warstwy klasyfikatora\n",
    "        # Dopasowanie wyjścia do liczby klas w zadaniu\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce31a6-4704-4fb1-a4f6-cb13451c865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearningModelInception(nn.Module):\n",
    "    def __init__(self, num_classes=9, pretrained=True):\n",
    "        super(TransferLearningModelInception, self).__init__()\n",
    "        \n",
    "        # Wczytanie pretrenowanego modelu Inception_v3\n",
    "        self.base_model = models.inception_v3(pretrained=pretrained, aux_logits=True)\n",
    "        \n",
    "        # Zastąpienie ostatniej w pełni połączonej warstwy klasyfikatora\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Inception_v3 wymaga rozdzielonych ścieżek dla danych treningowych i testowych\n",
    "        # Dla danych treningowych można wykorzystać aux_logits\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99f3c6-ba50-435a-bf2b-8f620a26434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearningModelSqueezenet(nn.Module):\n",
    "    def __init__(self, num_classes=9, pretrained=True):\n",
    "        super(TransferLearningModelSqueezenet, self).__init__()\n",
    "\n",
    "        # Wczytanie pretrenowanego SqueezeNet1_1\n",
    "        self.base_model = models.squeezenet1_1(pretrained=pretrained)\n",
    "\n",
    "        # Dostosowanie klasyfikatoraa\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Conv2d(512, num_classes, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Globalne uśrednianie\n",
    "        )\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec8988-e624-468d-b399-9a0564121c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferLearningModelDenseNet(nn.Module):\n",
    "    def __init__(self, num_classes=9, pretrained=True):\n",
    "        super(TransferLearningModelDenseNet, self).__init__()\n",
    "\n",
    "        # Wczytanie pretrenowanego DenseNet121\n",
    "        self.base_model = models.densenet121(pretrained=pretrained)\n",
    "\n",
    "        # Zastąpienie klasyfikatora\n",
    "        num_features = self.base_model.classifier.in_features\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d4405-5232-41e4-8186-a98fbda940be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71012c1-f712-4b4e-bfb0-9d132b6aa669",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedModel(nn.Module):\n",
    "    def __init__(self, num_classes=9, input_shape=(3, 64, 64)):\n",
    "        super(AdvancedModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "\n",
    "        # Obliczenie wymiaru wyjściowego dla klasyfikatora\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_shape)\n",
    "            dummy_output = self.features(dummy_input)\n",
    "            flattened_size = dummy_output.view(1, -1).size(1)\n",
    "            print(f\"Flattened size: {flattened_size}\")  # Debug: Sprawdzenie wymiarów\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(flattened_size, 256),  # Dynamiczny rozmiar wyjściowy\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f\"Input shape: {x.shape}\")  # Debugowanie: rozmiar wejściowy\n",
    "        x = self.features(x)\n",
    "        # print(f\"Features output shape: {x.shape}\")  # Rozmiar po bloku features\n",
    "        x = self.classifier(x)\n",
    "        # print(f\"Classifier output shape: {x.shape}\")  # Rozmiar po klasyfikatorze\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a074edf6-8596-4abc-848a-154fa73b4ed2",
   "metadata": {},
   "source": [
    "### Initialization of the model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d688051-b6ae-4024-8f63-861d3ea53a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransferLearningModelSqueezenet(num_classes=9).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d134e8d-af30-4fc3-8191-a8d9ed4bf9a6",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb52288-14a9-4b64-a42e-5d7106547c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8654bdca-d461-42ab-bf8e-eec15489cde3",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04b810-54f0-4018-89cf-aeb6fe509e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './modele/Squeezenet2501.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e4afa4-3a01-4b41-b46a-32e4c1bd62e1",
   "metadata": {},
   "source": [
    "### Disconnect Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45f344-3e80-4bbe-b13f-c6f194978e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
